"""Report templates for Milvus import performance analysis."""

from typing import Any

COMPREHENSIVE_REPORT_TEMPLATE = """
# Milvus Import Performance Report

## Executive Summary
{executive_summary}

## Performance Metrics

### Import Timeline
{import_timeline}

### Throughput Analysis
{throughput_analysis}

## Resource Utilization

### Compute Resources
{compute_resources}

### Storage Performance
{storage_performance}

## Performance Analysis

### Bottleneck Identification
{bottleneck_analysis}

### Anomaly Detection
{anomaly_detection}

## Optimization Recommendations

### Immediate Actions
{immediate_actions}

### Long-term Improvements
{longterm_improvements}

## Technical Details
{technical_details}
"""


GLM_ANALYSIS_PROMPT = """Generate a Milvus import performance report. Focus on extracting numeric metrics from the provided JSON data.

## Input Data Structure:
{data_json}

## CRITICAL: Prometheus Metrics Extraction
The prometheus_metrics.raw_queries contains metrics with this structure:
- Path: prometheus_metrics.raw_queries.[metric_name].response.data.result[0].values
- Values format: [[timestamp, "value"], [timestamp, "value"], ...]
- Extract the second element (value) from each pair and convert to float

### Required Calculations:
For memory (milvus_memory): Convert bytes to GB by dividing by 1073741824
For CPU (milvus_cpu): Show as decimal (0.5 = 50% or 0.5 cores)
For IOPS: Average the values directly
For bytes: Convert to MB/s by dividing by 1048576

## Report Sections:

### 1. Import Summary
Extract from import_info and metadata:
- Job ID: First element of job_ids array
- Collection: collection_name field
- Status: status field (completed/failed)
- Duration: total_duration_seconds (format as X.XX seconds)
- Data Volume: total_rows (with thousand separators)
- Data Size: file_info.total_size_bytes (convert to GB)

### 2. Performance Timeline
Search loki_logs for entries containing "jobTimeCost":
- Pattern: [jobTimeCost/PHASE=DURATION]
- Extract phase name and duration
- Calculate percentage of total time
- Sort by timestamp
Create table: | Phase | Duration | Percentage |

### 3. Resource Metrics Analysis
From prometheus_metrics.raw_queries, for each metric:

| Metric Type | Average | Minimum | Maximum | Unit |
|-------------|---------|---------|---------|------|
| Memory (milvus_memory) | Calculate from values | Min value | Max value | GB |
| CPU (milvus_cpu) | Calculate from values | Min value | Max value | cores |
| Read IOPS (minio_read_iops) | Calculate from values | Min value | Max value | ops/s |
| Write IOPS (minio_write_iops) | Calculate from values | Min value | Max value | ops/s |
| Read Throughput (minio_read_bytes) | Calculate from values | Min value | Max value | MB/s |
| Write Throughput (minio_write_bytes) | Calculate from values | Min value | Max value | MB/s |

### 4. Performance Indicators
Calculate and display:
- Import Throughput: total_rows / total_duration_seconds (rows/sec)
- Data Processing Rate: total_size_bytes / total_duration_seconds / 1048576 (MB/s)
- Memory Efficiency: peak_memory / average_memory ratio
- Resource Utilization: CPU and memory usage patterns

### 5. Data Configuration
From import_info:
- File count and types
- Schema configuration
- Test parameters

### 6. Key Events
From loki_logs:
- List errors (if any)
- Show completion timestamps for each phase

Format all numbers appropriately (2 decimal places for decimals, thousand separators for large numbers)."""


def format_analysis_report(
    glm_response: str, raw_data: dict[str, Any], model_name: str = "GLM"
) -> str:
    """Format the final analysis report with GLM response and additional context.
    
    Args:
        glm_response: The analysis result from GLM
        raw_data: The raw data dictionary
        model_name: The actual GLM model used (e.g., 'glm-4.5', 'glm-4.5-air', 'glm-4-flash')
    """

    # The GLM response should already be well-formatted markdown
    # We can add a header/footer if needed

    # Format model name for display
    display_model = model_name.upper().replace("-", " ")
    
    header = f"<!-- Generated by Milvus Import Analyzer with {display_model} -->\n"

    footer = f"\n\n---\n*Report generated using {display_model} analysis engine*\n"

    if "metadata" in raw_data:
        meta = raw_data["metadata"]
        if meta.get("job_ids"):
            footer += f"*Job IDs: {', '.join(meta['job_ids'])}*\n"

    return header + glm_response + footer
